---
title: "Model averaging in drc"
output: 
  learnr::tutorial:
    css: "css/style.css"
    progressive: false
    allow_skip: true
runtime: shiny_prerendered
bibliography: bayesnec.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = F)
library(drc)
library(tidyverse)

load("vignettes/ametryn.RData")
```

## Background

We've learned how to fit a model with `drm`, check how well it fits with `summary`, and compare it to other models using goodness of fit statistics with `mselect`. We have also calculated an ECx value using the `ED` function. Now we're going calculate a model-averaged ECx value using a new dataset that looks at the toxicity of a herbicide, ametryn to something photosynthetic.  


```{r ametryn, echo=TRUE}
herbtox<- ametryn
head(herbtox,3)
```
The data have three columns, one with the herbicide name, one with concentrations (log10 transformed) and one with our response variable, fvfm, which is a measure of photosynthetic efficiency. 

To keep the data simple, let's back transform the concentration to regular values before fitting our model. We can do this using the *mutate* function (from the `tidyverse` packages), which adds a column to our dataframe after it does the math we tell it to do. 

We know that the data has a lower response limit of 0 so we can use a 3-parameter model. 


```{r data fix, echo=TRUE}
herbtox<- herbtox %>% 
  mutate(x=10^concentration)

head(herbtox, 3)

ametryn_LL3 <-  drm(fvfm~x, data=herbtox, fct=LL.3(names = c("Slope","Upper Limit", "Midpoint")))

plot(ametryn_LL3, type="all")

```
We can use the *mselect* function again to help choose the best model to fit. Comparing fits, we can see the LL.3(), LN.4(), or W2.3() models are comparable.  

```{r mselect ametryn, echo=TRUE}
mselect(ametryn_LL3, fctList = list(W1.3(),W2.3(), LN.3(), NEC.3(),W1.4(),W2.4(), LN.4(), NEC.4()),linreg=TRUE) 
```
We could calculate ECx values using these models individually, but we would have to run and save each model individually to pass to the `ED` function. This is cumbersome and does not answer which is best to use. 

```{r ED ametryn, echo=TRUE}
ametryn_W23 <-  drm(fvfm~x, data=herbtox, fct=W2.3(names = c("Slope","Upper Limit", "Midpoint")))

ED(ametryn_LL3, c(50), interval="delta")
ED(ametryn_W23, c(50), interval="delta")

```

## Model averaging ED values 

If you're not sure which model to use to calculate an ECx value, say if there are multiple models with comparable fits but different ECx values, a robust approach would be to calculate a model average based on the individual models weighted by how well they fit the data. The function in the `drc` package for this is called model averaging effective doses `maED`.

The function's arguments include a starting model, a list of models you want to average, the ED values you're after, and a method to calculate the confidence intervals. This is different to the confidence interval above because we're combining model predictions. There are two methods "kang" and "buckland" described in the package documentation. I normally go with Kang because I prefer the sound of confidence intervals based on "weighted means of confidence intervals for the individual fits" compared to "approximate variance formula under the assumption of perfectly correlated estimates". This *vibe* is not sound statistical advice. 


Let's take our model list again and see the model average. Note that the NEC models cannot be included in a maED framework. 


```{r maed, echo=TRUE}
maED(ametryn_LL3, 
    list(W1.3(),W2.3(), LN.3(),W1.4(),W2.4(), LN.4()),
    c(50), #multiple ECx values can be inputted here
    interval="kang")
```

Our model average EC50 is 2.1 (1.8 - 2.4). Most of this value comes from LL.3 (~60% weight) and LN.4 (~40% weight). 

Note that we don't have a model average model fit to plot (like `Bayesnec` does). Instead we can report the model averaged ECx value and plot one of the highly weighted models (or all the highly weighted models). 


